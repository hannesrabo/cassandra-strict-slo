* YCSB load testing
** Important points to remember

   - CDF distribution curves at different loads on *vanilla Cassandra*
     + Create script that benchmarks different *ops/sec*.
   - CDF distribution curves at different loads using *different mitigation strategies*
     + Speculative retries
     + Request duplication

** What to find out

   - How to *create plots* based on the raw data.
     + Create .csv file.
   - Get more output from YCSB
   - Which *workload* is the most appropriate to run?

** How to run YCSB

  _Starting up Cassandra in Mininet shell_
    // Check that the Cassandra nodes are up and running
    h1 ../cassandra/bin/nodetool status
    // Cassandra currently running on h1 and h2

  _Run YCSB_
    xterm h3 // Run YCSB on this node

** Running a workload

   Adapted from
   [[https://github.com/brianfrankcooper/YCSB/wiki/Running-a-Workload][Running a Workload]]
   [[https://github.com/brianfrankcooper/YCSB/wiki/Using-the-Database-Libraries][Using the Database Libraries]]

   1) Set up the database system to test
   2) Choose the appropriate DB interface layer
   3) Choose the appropriate workload
   4) Choose the appropriate runtime parameters (number of client threads, target throughput, etc.)
   5) Load the data
   6) Execute the workload

   Before the YCSB Client runs, the tables must be created, since the Client itself will not request to create the tables.
 The tables that must be created depends on the workload.
 The DB interface layer is a java class that execute read, insert, update, delete and scan calls generated by the YCSB Client into calls against your database's API.
 Be sure to list all the hostnames, so that the *client can load balance* its connections among all of the servers.

 Typically, a workload is a combination of:
     - Workload java class (subclass of com.yahoo.ycsb.Workload)
     - Parameter file (in the Java Properties format)

 Because the properties of the dataset must be known during the loading phase (so that the proper kind of record can be constructed and inserted) and during the transaction phase (so that the correct record ids and fields can be referred to) a single set of properties is shared among both phases. Thus the parameter file is used in both phases.

*** Choosing and preparing a workload

 The CoreWorkload is a package of standard workloads that is distributed with the YCSB and can be used directly. In particular, the CoreWorkload defines a simple mix of read/insert/update/scan operations. *The relative frequency* of *each operation* is *defined in* the *parameter file*, as are other properties of the workload. Thus, *by changing the parameter file*, a variety of different concrete workloads can be executed. For more details on the CoreWorkload, see Core Workloads.

 A variety of workloads can be found [[https://github.com/brianfrankcooper/YCSB/wiki/Core-Workloads][here]]. They can be easily tweaked by corresponding parameters files in the workload directory.

Important parameters:
    -target specifies *number of operations per second*

Parameters that could be interesting for us to adjust:
    - recordcount
    - *requestdistribution*

*** Run the workload

./bin/ycsb run basic -P workloads/workloadb -threads 1 > transactions.dat
./bin/ycsb load cassandra2-cql -p hosts='100.0.0.11,100.0.0.12' -threads 1 -P workloads/workloadb -s > workloadB.out

** What we probably would like to do next

Tailor our first workload:

Use Workload B 95/5 reads/write mix.
Add the following properties to the parameters file:

// hdrhistogram is to coarse grained for us. We need a granularity of at least 100th of every percent. We therefore need to use a histogram and convert to percentages ourselves.

measurementtype=histogram
